{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8cbf91",
   "metadata": {},
   "source": [
    "# Testing in Python\n",
    "\n",
    "This notebook covers fundamental aspects of **Testing** in Python:\n",
    "\n",
    "1. **Unit Testing**\n",
    "2. **Integration Testing**\n",
    "3. **Mocking**\n",
    "\n",
    "Testing ensures our code works as intended, remains stable as it evolves, and catches regressions or bugs early in the development process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155db6fb",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Unit Testing](#unit-testing)\n",
    "2. [Integration Testing](#integration-testing)\n",
    "3. [Mocking](#mocking)\n",
    "\n",
    "We'll include code examples using Python's built-in **unittest** framework along with some notes on **pytest** where relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aecdcd",
   "metadata": {},
   "source": [
    "## 1. Unit Testing <a name=\"unit-testing\"></a>\n",
    "\n",
    "### What is Unit Testing?\n",
    "Unit tests focus on **individual units** of code—often functions or methods. Each test aims to verify that one small \"unit\" works correctly in isolation.\n",
    "\n",
    "**Key Points**:\n",
    "- Each test typically checks a single logical aspect (e.g., function input -> expected output).\n",
    "- Unit tests are fast, isolated, and form the foundation of the testing pyramid.\n",
    "\n",
    "### Example Project Setup\n",
    "Consider a Python module `math_utils.py` with a few simple functions:\n",
    "\n",
    "```python\n",
    "# math_utils.py\n",
    "\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def divide(a, b):\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero\")\n",
    "    return a / b\n",
    "```\n",
    "\n",
    "We want to create a test module `test_math_utils.py` to verify these functions' correctness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e490fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "# For demonstration in this notebook, let's define math_utils here\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def divide(a, b):\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero\")\n",
    "    return a / b\n",
    "\n",
    "class TestMathUtils(unittest.TestCase):\n",
    "\n",
    "    def test_add_positive_numbers(self):\n",
    "        self.assertEqual(add(2, 3), 5)\n",
    "        self.assertEqual(add(0, 10), 10)\n",
    "\n",
    "    def test_add_negative_numbers(self):\n",
    "        self.assertEqual(add(-1, -2), -3)\n",
    "        self.assertEqual(add(-5, 5), 0)\n",
    "\n",
    "    def test_divide_normal_cases(self):\n",
    "        self.assertAlmostEqual(divide(10, 2), 5.0)\n",
    "        self.assertAlmostEqual(divide(-10, 2), -5.0)\n",
    "\n",
    "    def test_divide_by_zero(self):\n",
    "        with self.assertRaises(ValueError):\n",
    "            divide(5, 0)\n",
    "\n",
    "# We can run tests programmatically:\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ab713d",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- We define a test class (`TestMathUtils`) inheriting from `unittest.TestCase`.\n",
    "- Each method starting with `test_` is automatically recognized as a test.\n",
    "- We use **assertions** like `assertEqual` to check expected vs. actual behavior.\n",
    "- `with self.assertRaises(...)` checks that a specific exception is raised.\n",
    "- Normally, you'd keep tests in a separate file from your main code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ef5a59",
   "metadata": {},
   "source": [
    "## 2. Integration Testing <a name=\"integration-testing\"></a>\n",
    "\n",
    "**Integration Tests** verify that multiple components or modules work together as expected. They may test:\n",
    "- Interactions between functions, classes, or modules.\n",
    "- External services (APIs, databases).\n",
    "- The flow of data through multiple layers of an application.\n",
    "\n",
    "### Example Scenario\n",
    "Imagine we have a function that reads data from one module, processes it with another, and returns combined results. For demonstration, we’ll just pretend to integrate two simple modules (though typically you'd see more complexity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d077e542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.005s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def fetch_data():\n",
    "    \"\"\"\n",
    "    Pretend this function fetches data from an external source.\n",
    "    We'll mock this out in tests.\n",
    "    \"\"\"\n",
    "    return [random.randint(1, 100) for _ in range(5)]\n",
    "\n",
    "def process_data(data_list):\n",
    "    \"\"\"\n",
    "    Simple function that returns (sum, avg).\n",
    "    \"\"\"\n",
    "    if not data_list:\n",
    "        return 0, 0\n",
    "    total = sum(data_list)\n",
    "    avg = total / len(data_list)\n",
    "    return total, avg\n",
    "\n",
    "def combined_workflow():\n",
    "    \"\"\"\n",
    "    Integration function that fetches data and then processes it.\n",
    "    \"\"\"\n",
    "    data = fetch_data()\n",
    "    return process_data(data)\n",
    "\n",
    "# Let's test them in an \"integration\" sense.\n",
    "import unittest\n",
    "\n",
    "class TestIntegration(unittest.TestCase):\n",
    "\n",
    "    def test_integration_normal(self):\n",
    "        \"\"\"Test the entire workflow without mocking\"\"\"\n",
    "        total, avg = combined_workflow()\n",
    "        # We can't predict exact random values, but we can check ranges.\n",
    "        self.assertTrue(0 < total <= 500)  # 5 random ints, each up to 100\n",
    "        self.assertTrue(0 < avg <= 100)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd1ea9",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- `combined_workflow()` calls both `fetch_data()` and `process_data()`. This is an **integration** because multiple parts are being used together.\n",
    "- **In production** or more complex scenarios, you might integrate with databases, message queues, or external APIs here.\n",
    "- The test checks that the result is within expected bounds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed2a52",
   "metadata": {},
   "source": [
    "## 3. Mocking <a name=\"mocking\"></a>\n",
    "\n",
    "**Mocking** is the practice of replacing real objects with \"fake\" ones (mocks) that simulate their behavior. This is critical when:\n",
    "- You want **isolation** (e.g., no real network calls, no real database writes).\n",
    "- External dependencies are slow, unavailable, or expensive.\n",
    "- Reproducible tests with predictable results.\n",
    "\n",
    "### Python Tools for Mocking\n",
    "- `unittest.mock` (built into Python)\n",
    "- `pytest-mock` (for pytest users)\n",
    "\n",
    "Let’s see how to mock the `fetch_data()` function so our integration test doesn’t rely on random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "087f4f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.005s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "from unittest.mock import patch\n",
    "import unittest\n",
    "\n",
    "# We'll reuse the same combined_workflow, but mock fetch_data.\n",
    "\n",
    "class TestMocking(unittest.TestCase):\n",
    "\n",
    "    @patch('__main__.fetch_data', return_value=[10, 20, 30, 40, 50])\n",
    "    def test_mocked_workflow(self, mock_fetch):\n",
    "        total, avg = combined_workflow()\n",
    "        # Because we know the returned list is [10, 20, 30, 40, 50],\n",
    "        # we can check precise results.\n",
    "        self.assertEqual(total, 150)\n",
    "        self.assertEqual(avg, 30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9219d0",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "- We use `@patch('__main__.fetch_data', return_value=[10, 20, 30, 40, 50])` to replace `fetch_data()` with a mock returning `[10, 20, 30, 40, 50]`.\n",
    "- Now our test is **deterministic**—we know exactly what data is used.\n",
    "- This is **unit-testing** or **integration-testing** with mocks to isolate external dependencies.\n",
    "\n",
    "In real scenarios, you'd mock out **network calls**, **database queries**, or **file I/O** to keep tests fast and deterministic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309c4cd1",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we've covered:\n",
    "1. **Unit Testing**: Testing individual functions using `unittest`.\n",
    "2. **Integration Testing**: Ensuring multiple pieces work together, possibly including external services.\n",
    "3. **Mocking**: Replacing real objects/functions with mocks for isolation and deterministic tests.\n",
    "\n",
    "## Further Suggestions\n",
    "- Explore **pytest** for a more concise testing syntax.\n",
    "- Use **coverage** tools (like `coverage.py`) to measure how much of your code is tested.\n",
    "- Integrate your tests into CI/CD pipelines to run automatically on each commit.\n",
    "\n",
    "With robust testing, you can develop more confidently, knowing that your code remains stable and correct as it evolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d8e9c-b1e9-4c66-a612-61a7cea8bb21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "name": "Testing.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
